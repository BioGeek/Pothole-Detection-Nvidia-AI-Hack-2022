{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddca83a8",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b113e10-1b6d-449b-b712-f79f3f610ef5",
   "metadata": {},
   "source": [
    "# Preparation for Model Training #\n",
    "We noticed some issues with the TrafficCamNet model for our video AI application. It's likely that the model wasn't trained for our exact parking garage use case. For the remaining of the lab, we will use the TAO Toolkit to fine-tune the model so that it can adapt to our environment. Below is what a typical model development workflow looks like. We start by preparing a pre-trained model and the data. Next, we prepare the configuration file(s) and begin to train the model with new data and evaluate its performance. We export the model once its satisfactory. Note that this does not include inference optimization steps, which is very important for video AI applications that are deployed on edge devices. \n",
    "<p><img src='images/pre-trained_model_workflow.png' width=1080></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1934605-75a4-49fa-9a5d-214f4a001400",
   "metadata": {},
   "source": [
    "## Learning Objectives ##\n",
    "In this notebook, you will learn how to prepare for training a video AI model using the TAO Toolkit, including: \n",
    "* Understanding Model Specification\n",
    "* Preparing Data for TAO Toolkit Consumption\n",
    "* Editing Spec Files for TAO Toolkit Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756103b-e433-42e4-a9ec-9245d6a64b51",
   "metadata": {},
   "source": [
    "**Table of Contents**<br>\n",
    "This notebook covers the below sections: \n",
    "1. [Detectnet_v2 Object Detection Model](#s1)\n",
    "    * [Directory Structure](#s1.1)\n",
    "    * [Model Objective](#s1.2)\n",
    "2. [Prepare Pre-trained Model](#s2)\n",
    "    * [Exercise #1 - Review Model Card](#e1)\n",
    "3. [Prepare Data Set](#s3)\n",
    "    * [Annotation](#s3.1)\n",
    "    * [Exploratory Data Analysis](#s3.2)\n",
    "    * [Covert Video File into Frame Images](#s3.3)\n",
    "    * [Generate Labels](#s3.4)\n",
    "    * [Converting to TFRecords](#s3.5)\n",
    "    * [Exercise #2 Dataset Convert](#e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4fcd16-3d29-405d-b032-6b48226dad63",
   "metadata": {},
   "source": [
    "<a name='s1'></a>\n",
    "## DetectNet_v2 Object Detection Model ##\n",
    "As we previously learned, the [TrafficCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/models/tlt_trafficcamnet) purpose-built model is based on NVIDIA DetectNet_v2 detector with ResNet18 as a feature extractor. As such, we will use the `detectnet_v2` task, which supports the following subtasks: \n",
    "* `dataset_convert`\n",
    "* `train`\n",
    "* `evaluate`\n",
    "* `inference`\n",
    "* `prune`\n",
    "* `calibration_tensorfile`\n",
    "* `export`\n",
    "\n",
    "<p><img src='images/rewind.png' width=720><p>\n",
    "    \n",
    "These subtasks can be invoked using the convention `detectnet_v2 <subtask> <args_per_subtask>` on the command-line. Additionally, we can always find more information about these subtasks with `detector_v2 <subtask> --help`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259d244-84ef-44ff-a389-d4a6eeab7571",
   "metadata": {},
   "source": [
    "<a name='s1.1'></a>\n",
    "### Directory Structure ###\n",
    "We will use the below structure for our project, where the `tao_project` directory will hold most of the assets related to model training and outputs. \n",
    "\n",
    "<p><img src='images/project_structure.png' width=740></p>\n",
    "\n",
    "* The current directory is `/dli/task`. When using paths, it is most reliable to use the absolute path that begins with `/dli/task` as some of the functions will otherwise try to reference the paths relative to where they are called. \n",
    "* The higher level `data` directory represents the raw video data, vs. the lower level `tao_project/data` directory represents the preprocessed data to be used for model training. \n",
    "* The higher level `images` directory contains graphics used in this course and are not related to the video AI model. \n",
    "* The `spec_files` directory holds spec files that will be used for TAO Toolkit model training as well as DeepStream `Gst-nvinfer` plugin configuration files. \n",
    "* The `tao_project/models` directory will hold different versions of the model as we work to arrive at a final, optimized, product. Each folder will hold the corresponding model file (e.g. `.tlt` or `.etlt`), as well as accompanied assets such as `labels.txt`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2370d9e-d605-46ab-b474-2db51ef29635",
   "metadata": {},
   "source": [
    "Execute the below cell to set and create directories for the TAO Toolkit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62b5c30-81b7-4a34-9789-b59614f44d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/dli/task/tao_project’: File exists\n",
      "mkdir: cannot create directory ‘/dli/task/tao_project/data’: File exists\n",
      "mkdir: cannot create directory ‘/dli/task/tao_project/models’: File exists\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Set and create directories for the TAO Toolkit experiment\n",
    "import os\n",
    "\n",
    "os.environ['PROJECT_DIR']='/dli/task/tao_project'\n",
    "os.environ['SOURCE_DATA_DIR']='/dli/task/data'\n",
    "os.environ['DATA_DIR']='/dli/task/tao_project/data'\n",
    "os.environ['MODELS_DIR']='/dli/task/tao_project/models'\n",
    "os.environ['SPEC_FILES_DIR']='/dli/task/spec_files'\n",
    "\n",
    "!mkdir $PROJECT_DIR\n",
    "!mkdir $DATA_DIR\n",
    "!mkdir $MODELS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4977de-9671-40ec-8324-d05803074c43",
   "metadata": {},
   "source": [
    "<a name='s1.2'></a>\n",
    "### Model Objective ###\n",
    "For our video AI application, we want to train a model that uses the TrafficCamNet as the starting point and provide it with additional (labeled) data so it can adapt to our specific camera angle, lighting condition, and other environmental conditions. We will be using the **unpruned pre-trained TrafficCamNet purpose-built model** as the starting point and training a custom **one-class Object Detection model** that is adapted to our use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a15e30",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='s2'></a>\n",
    "## Prepare Pre-trained Model and Data Set ##\n",
    "Developers typically begin by choosing and downloading a pre-trained model from [NGC](https://ngc.nvidia.com/) - either a highly accurate purpose-built model or just the pre-trained weights of the architecture of their choice. It's difficult to immediately identify which model/architecture will work best for a specific use case as there is often a tradeoff between time to train, accuracy, and inference performance. It is common to compare across multiple models before picking the best candidate.\n",
    "\n",
    "Here are some pointers that will help choose an appropriate model: \n",
    "* Look at the model inputs/outputs to decide if it will fit your use case. \n",
    "* Input format is also an important consideration. For example, TrafficCamNet, as well as other DetectNet_v2 models, expect the input to be 0-1 normalized with input channels in RGB order. Models that use a BGR order will require input preprocessing/mean subtraction that might result in suboptimal performance. \n",
    "\n",
    "We can use the `ngc registry model list <model_glob_string>` command to get a list of models that are hosted in the NGC model registry. For example, we can use `ngc registry model list nvidia/tao/*` to list all available models. The `--column` option identifies the columns of interest. More information about the NGC Registry CLI can be found in the [User Guide](https://docs.nvidia.com/dgx/pdf/ngc-registry-cli-user-guide.pdf). For each model, there is a pruned version that can be deployed as is or an unpruned version which can be used to re-train with more data for specific use cases. We will use the unpruned version as a start for training purposes. The `ngc registry model download-version <org>/[<team>/]<model-name:version>` command will download the model from the registry. It has a `--dest` option to specify the path to download directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8730b58",
   "metadata": {},
   "source": [
    "<a name='e1'></a>\n",
    "#### Exercise #1 - Review Model Cards ####\n",
    "Let's download a pre-trained model. \n",
    "\n",
    "**Instructions**:<br>\n",
    "* Review the model cards for [TrafficCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/models/tlt_trafficcamnet) and/or [DetectNet_v2](https://catalog.ngc.nvidia.com/orgs/nvidia/models/tlt_pretrained_detectnet_v2) models to understand where you can find important model specifications. \n",
    "* Execute the below cell to download the NGC CLI. \n",
    "* Execute the following cell to list all available models. \n",
    "* Execute the following cell to download the TrafficCamNet model. \n",
    "* Execute the following cell to check if the model has been downloaded. \n",
    "* Execute the following cell to create `labels.txt` if it doesn't exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88994507",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLI=ngccli_cat_linux.zip\n",
      "--2022-08-30 03:39:33--  https://ngc.nvidia.com/downloads/ngccli_cat_linux.zip\n",
      "Resolving ngc.nvidia.com (ngc.nvidia.com)... 18.165.83.59, 18.165.83.119, 18.165.83.111, ...\n",
      "Connecting to ngc.nvidia.com (ngc.nvidia.com)|18.165.83.59|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34014460 (32M) [application/zip]\n",
      "Saving to: ‘ngc_assets/ngccli/ngccli_cat_linux.zip’\n",
      "\n",
      "ngccli_cat_linux.zi 100%[===================>]  32.44M   142MB/s    in 0.2s    \n",
      "\n",
      "2022-08-30 03:39:33 (142 MB/s) - ‘ngc_assets/ngccli/ngccli_cat_linux.zip’ saved [34014460/34014460]\n",
      "\n",
      "Archive:  ngc_assets/ngccli/ngccli_cat_linux.zip\n",
      "   creating: ngc_assets/ngccli/ngc-cli/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/yarl/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/yarl/_quoting_c.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libselinux.so.1  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/direct_url.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/top_level.txt  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/METADATA  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/COPYING  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/RECORD  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/WHEEL  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/INSTALLER  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/REQUESTED  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/lib-dynload/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_queue.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_bisect.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/binascii.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/unicodedata.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_jp.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_sha512.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_csv.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/pyexpat.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_ssl.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_sha256.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_socket.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/mmap.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_sha3.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/zlib.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_posixshmem.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/termios.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_hk.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_multibytecodec.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_struct.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/array.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_contextvars.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_decimal.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/fcntl.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/grp.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_tw.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_iso2022.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_multiprocessing.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/select.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_posixsubprocess.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/resource.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_opcode.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_cn.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_pickle.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_hashlib.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_json.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_datetime.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_sha1.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_md5.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_blake2.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_kr.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_random.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_elementtree.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_statistics.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/math.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/lib-dynload/_heapq.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libfreebl3.so  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/cryptography/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/cryptography/hazmat/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/cryptography/hazmat/bindings/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/cryptography/hazmat/bindings/_rust.abi3.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/cryptography/hazmat/bindings/_openssl.abi3.so  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/aiohttp/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/aiohttp/_http_parser.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/aiohttp/_websocket.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/aiohttp/_helpers.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/aiohttp/_http_writer.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/LICENSE  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/top_level.txt  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/METADATA  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/RECORD  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/WHEEL  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/LICENSE.APACHE  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/INSTALLER  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/LICENSE.BSD  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/LICENSE.PSF  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/direct_url.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/LICENSE  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/top_level.txt  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/METADATA  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/RECORD  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/WHEEL  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/INSTALLER  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/REQUESTED  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libgcc_s.so.1  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libcom_err.so.2  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libssl.so.10  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/frozenlist/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/frozenlist/_frozenlist.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libffi.so.6  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/grpc/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/grpc/_cython/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/grpc/_cython/cygrpc.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/grpc/_cython/_credentials/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/grpc/_cython/_credentials/roots.pem  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/google/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/google/protobuf/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/google/protobuf/internal/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/google/protobuf/internal/_api_implementation.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/google/protobuf/pyext/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/google/protobuf/pyext/_message.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libffi-9c61262e.so.8.1.0  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libz.so.1  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/_cffi_backend.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/cacert.pem  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ivs/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sns/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/amp/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sts/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/paginators-1.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/transfer/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ecs/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ram/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appstream/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/backup/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/service-2.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sms/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mq/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/outposts/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/glue/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/budgets/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/swf/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/shield/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/s3/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/emr/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/logs/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/amplify/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/worklink/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/worklink/2018-09-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/worklink/2018-09-25/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/worklink/2018-09-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/qldb/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/polly/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/batch/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dms/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/account/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/schemas/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iam/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appsync/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mobile/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mobile/2017-07-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mobile/2017-07-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mobile/2017-07-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mobile/2017-07-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/eks/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/service-2.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/nimble/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/nimble/2020-08-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/nimble/2020-08-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/nimble/2020-08-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/nimble/2020-08-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/es/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/paginators-1.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dax/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/workmail/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/glacier/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/datasync/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar/2017-04-19/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar/2017-04-19/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar/2017-04-19/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar/2017-04-19/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/2018-09-05/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/2018-09-05/service-2.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/2018-09-05/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/2018-09-05/service-2.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/organizations/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/paginators-1.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appflow/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/location/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/snowball/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/textract/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/grafana/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ds/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/fis/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sdb/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dlm/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/waf/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/importexport/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lambda/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2014-11-11/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2014-11-11/service-2.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elb/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/panorama/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/neptune/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/service-2.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/connect/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pi/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/support/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/endpoints.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/macie2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ses/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ebs/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/docdb/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/service-2.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/service-2.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/medialive/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/service-2.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ce/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2011-02-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2011-02-01/service-2.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/translate/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/signer/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/databrew/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mgn/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/_retry.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sqs/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mgh/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kms/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/detective/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/acm/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/events/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/events/2014-02-03/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/events/2014-02-03/service-2.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kafka/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/s3control/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pricing/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/paginators-1.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sso/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/paginators-1.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/xray/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/firehose/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/fms/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cur/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/proton/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/fsx/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/inspector/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2015-08-18/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2015-08-18/service-2.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/service-2.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/finspace/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/health/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/chime/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/macie/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/macie/2017-12-19/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/macie/2017-12-19/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/macie/2017-12-19/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/macie/2017-12-19/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mturk/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kendra/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/discovery/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/2017-11-09/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/2017-11-09/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/2017-11-09/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/2017-11-09/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/2020-03-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/2020-03-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/2020-03-01/paginators-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/2020-03-01/paginators-1.sdk-extras.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/config/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/efs/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/athena/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/braket/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/examples-1.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/waiters-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/forecast/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/service-2.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/service-2.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/paginators-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/psutil/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/psutil/_psutil_linux.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/psutil/_psutil_posix.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libpcre.so.1  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/examples/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/examples/cloudfront.rst  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/examples/s3.rst  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/cloudwatch/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/cloudwatch/2010-08-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/cloudwatch/2010-08-01/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/sns/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/sns/2010-03-31/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/sns/2010-03-31/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/cloudformation/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/cloudformation/2010-05-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/cloudformation/2010-05-15/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/s3/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/s3/2006-03-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/s3/2006-03-01/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/iam/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/iam/2010-05-08/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/iam/2010-05-08/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/glacier/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/glacier/2012-06-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/glacier/2012-06-01/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/sqs/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/sqs/2012-11-05/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/sqs/2012-11-05/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/dynamodb/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/dynamodb/2012-08-10/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/dynamodb/2012-08-10/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/opsworks/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/opsworks/2013-02-18/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/opsworks/2013-02-18/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-09-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-09-15/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-03-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-03-01/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-04-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-04-01/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2014-10-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2014-10-01/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-10-01/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-10-01/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-11-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-11-15/resources-1.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-04-15/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-04-15/resources-1.json  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/base_library.zip  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libgssapi_krb5.so.2  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libkrb5support.so.0  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libkrb5.so.3  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libk5crypto.so.3  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libcrypto.so.10  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/ngc  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/wcwidth/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/wcwidth/version.json  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/thrift/\n",
      "   creating: ngc_assets/ngccli/ngc-cli/thrift/protocol/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/thrift/protocol/fastbinary.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/multidict/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/multidict/_multidict.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libkeyutils.so.1  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libstdc++.so.6  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/certifi/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/certifi/cacert.pem  \n",
      "   creating: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/\n",
      "  inflating: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/direct_url.json  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/LICENSE  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/top_level.txt  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/namespace_packages.txt  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/METADATA  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/RECORD  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/WHEEL  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/INSTALLER  \n",
      " extracting: ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/REQUESTED  \n",
      "  inflating: ngc_assets/ngccli/ngc-cli/libpython3.9.so.1.0  \n",
      " extracting: ngc_assets/ngccli/ngc-cli.md5  \n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Download the NGC CLI\n",
    "%env CLI=ngccli_cat_linux.zip\n",
    "!mkdir -p ngc_assets/ngccli\n",
    "!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P ngc_assets/ngccli\n",
    "!unzip -u \"ngc_assets/ngccli/$CLI\" \\\n",
    "       -d ngc_assets/ngccli/\n",
    "!rm ngc_assets/ngccli/*.zip \n",
    "os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(\"ngc_assets\", os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d1394b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"application\": \"Gaze Detection\",\n",
      "    \"createdDate\": \"2021-08-20T03:53:17.042Z\",\n",
      "    \"description\": \"Detect a persons eye gaze point of regard and gaze vector.\",\n",
      "    \"displayName\": \"Gaze Estimation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Computer Vision\",\n",
      "                \"Eye gaze estimation\",\n",
      "                \"Robotics\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 18282352,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"gazenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-01-13T18:59:31.540Z\"\n",
      "},{\n",
      "    \"application\": \"HeartRateNet Estimation\",\n",
      "    \"createdDate\": \"2021-08-20T20:50:01.480Z\",\n",
      "    \"description\": \"Estimate heart-rate non-invasively from RGB facial videos.\",\n",
      "    \"displayName\": \"HeartRateNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Heart Rate estimation\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"Computer Vision\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 588677,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"heartratenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-11-24T00:51:36.328Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:57.753Z\",\n",
      "    \"description\": \"Speech to Text Citrinet models for English.\",\n",
      "    \"displayName\": \"Speech to Text English Citrinet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v3.0\",\n",
      "    \"latestVersionSizeInBytes\": 566724116,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"speechtotext_english_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-03-26T03:24:49.050Z\"\n",
      "},{\n",
      "    \"application\": \"Punctuation and Capitalization\",\n",
      "    \"createdDate\": \"2021-08-18T20:05:02.000Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"Punctuation and Capitalization Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Punctuation\",\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Capitalization\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 438472343,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"punctuationcapitalization_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-03-26T03:24:29.890Z\"\n",
      "},{\n",
      "    \"application\": \"Joint Intent And Slot Classification\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-08T04:38:25.037Z\",\n",
      "    \"description\": \"Intent and Slot classification of the queries for the misty bot with DistilBert model trained on weather, smalltalk and POI (places of interest) data.\",\n",
      "    \"displayName\": \"Joint Intent and Slot Classification DistilBert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Natural Language Processing\",\n",
      "                \"Intent and slot classification\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 266351975,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"intentslotclassification_misty_english_distilbert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T04:50:25.861Z\"\n",
      "},{\n",
      "    \"application\": \"Fiducial Landmarks\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.371Z\",\n",
      "    \"description\": \"Detect fiducial keypoints from an image of a face.\",\n",
      "    \"displayName\": \"Facial Landmarks Estimation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Facial landmark estimation\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Computer Vision\",\n",
      "                \"Robotics\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v3.0\",\n",
      "    \"latestVersionSizeInBytes\": 2351014,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"fpenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-11-24T00:50:30.216Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T12:35:14.960Z\",\n",
      "    \"description\": \"English (en-GB) Conformer ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 488593412,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_gb_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-08-04T12:35:16.264Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:59.381Z\",\n",
      "    \"description\": \"Speech to Text Quartznet model for English.\",\n",
      "    \"displayName\": \"Speech to Text English QuartzNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"Quartznet\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
      "    \"latestVersionSizeInBytes\": 70904250,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"speechtotext_english_quartznet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-03-26T03:24:08.235Z\"\n",
      "},{\n",
      "    \"application\": \"Classification\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.190Z\",\n",
      "    \"description\": \"Resnet18 model to classify a car crop into 1 out 6 car types.\",\n",
      "    \"displayName\": \"VehicleTypeNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Image Classification\",\n",
      "                \"Object Detection\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Traffic\",\n",
      "                \"Public Safety\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Vehicle Classification\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 19980344,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"vehicletypenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-11-08T04:58:38.199Z\"\n",
      "},{\n",
      "    \"application\": \"Punctuation and Capitalization\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-31T21:38:24.169Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Punctuation\",\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"Conversational-Ai\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Capitalization\",\n",
      "                \"Inference\",\n",
      "                \"BERT\",\n",
      "                \"Finetuning\",\n",
      "                \"Natural-Language-Processing\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 438472343,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_en_us_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:43:53.336Z\"\n",
      "},{\n",
      "    \"application\": \"Speech To Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:25:16.549Z\",\n",
      "    \"description\": \"Base Mandarin 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Mandarin LM\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"lm\",\n",
      "                \"TAO\",\n",
      "                \"language Models\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Conversational AI\",\n",
      "                \"Mandarin\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"NA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 8461503449,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"arpa\",\n",
      "    \"name\": \"speechtotext_zh_cn_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"NA\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-07-19T08:38:35.860Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"createdDate\": \"2022-03-23T11:50:58.191Z\",\n",
      "    \"description\": \"German Conformer ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR German\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"German\",\n",
      "                \"Conformer\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 488591508,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechtotext_de_de_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-02T07:40:01.043Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T18:06:44.126Z\",\n",
      "    \"description\": \"English Quartznet ASR model trained on ASR set 1.2\",\n",
      "    \"displayName\": \"RIVA Quartznet ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"Quartznet\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
      "    \"latestVersionSizeInBytes\": 70904250,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_us_quartznet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:45:00.526Z\"\n",
      "},{\n",
      "    \"application\": \"Instance Segmentation\",\n",
      "    \"createdDate\": \"2021-08-16T16:34:42.327Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained Instance Segmentation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"MaskRCNN\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Robotics\",\n",
      "                \"Retail\",\n",
      "                \"Metropolis\",\n",
      "                \"CV\",\n",
      "                \"Instance Segmentation\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"resnet10\",\n",
      "    \"latestVersionSizeInBytes\": 40175904,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_instance_segmentation\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-09-20T21:30:44.113Z\"\n",
      "},{\n",
      "    \"application\": \"Question Answering\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:58.627Z\",\n",
      "    \"description\": \"Question Answering Bert Base uncased model for extractive question answering on any provided content.\",\n",
      "    \"displayName\": \"Question Answering SQUAD2.0 Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"QA\",\n",
      "                \"NLP\",\n",
      "                \"SQUAD2.0\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Question Answering\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 438459496,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"questionanswering_squad_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:00.138Z\"\n",
      "},{\n",
      "    \"application\": \"OTHER\",\n",
      "    \"createdDate\": \"2021-08-24T21:13:00.968Z\",\n",
      "    \"description\": \"Semantic segmentation of persons in an image.\",\n",
      "    \"displayName\": \"PeopleSemSegnet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Smart City\",\n",
      "                \"other\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"FP32\",\n",
      "                \"recipe\",\n",
      "                \"industry\",\n",
      "                \"HDF5\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"FP16\",\n",
      "                \"Retail\",\n",
      "                \"transfer-learning-toolkit\",\n",
      "                \"TLT\",\n",
      "                \"DeepStream\",\n",
      "                \"deep-learning\",\n",
      "                \"smart-cities\",\n",
      "                \"AI\",\n",
      "                \"INT8\",\n",
      "                \"technology\",\n",
      "                \"image-segmentation\",\n",
      "                \"computer-vision\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"application\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_quantized_vanilla_unet_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 124471635,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"peoplesemsegnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-08-22T18:55:53.936Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T17:15:39.660Z\",\n",
      "    \"description\": \"Spanish Citrinet ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR Spanish\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"STT\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Spanish\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"AMP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 566726427,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_es_us_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"AMP\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-02T07:34:20.885Z\"\n",
      "},{\n",
      "    \"application\": \"Semantic Segmentation\",\n",
      "    \"createdDate\": \"2021-08-16T16:34:42.315Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using Transfer Learning Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained Semantic Segmentation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Industrial\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Robotics\",\n",
      "                \"UNet\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Semantic Segmentation\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"vgg19\",\n",
      "    \"latestVersionSizeInBytes\": 161183816,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_semantic_segmentation\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-09-20T21:30:44.387Z\"\n",
      "},{\n",
      "    \"application\": \"Action Recognition\",\n",
      "    \"createdDate\": \"2021-10-22T18:24:05.069Z\",\n",
      "    \"description\": \"5 class action recognition network to recognize what people do in an image.\",\n",
      "    \"displayName\": \"Action Recognition Net\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"AI\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 310814833,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"actionrecognitionnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-17T00:31:18.396Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-07-21T20:09:28.480Z\",\n",
      "    \"description\": \"For each word in the input text, the model predicts a punctuation mark that should follow the word (if any), the model supports commas, poornvirams, exclaimation marks and question marks.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for Hindi\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 882514166,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_hi_in_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-07-21T21:37:36.030Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:53:38.516Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained Object Detection\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DSSD\",\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Industrial\",\n",
      "                \"SSD\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"EfficientNet\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"ResNet\",\n",
      "                \"YOLO\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"FasterRCNN\",\n",
      "                \"TLT\",\n",
      "                \"RetinaNet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"cspdarknet_tiny\",\n",
      "    \"latestVersionSizeInBytes\": 29955696,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_object_detection\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-06-03T23:37:04.905Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T07:11:42.166Z\",\n",
      "    \"description\": \"Mandarin (zh-CN) Conformer ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Mandarin\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v3.0\",\n",
      "    \"latestVersionSizeInBytes\": 478130474,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_zh_cn_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-08-11T05:21:31.776Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"createdDate\": \"2021-08-25T15:59:16.226Z\",\n",
      "    \"description\": \"Universal waveform generator from mel-spectrograms.\",\n",
      "    \"displayName\": \"Speech Synthesis Waveglow\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Text to Speech\",\n",
      "                \"TTS\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Waveglow\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 342214978,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_waveglow\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:11.922Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T17:17:07.715Z\",\n",
      "    \"description\": \"German Citrinet ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR German\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"STT\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"German\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 566726189,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_de_de_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-02T08:02:12.892Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T09:06:14.477Z\",\n",
      "    \"description\": \"Base English 3-gram LM\",\n",
      "    \"displayName\": \"Riva ASR English(en-GB) LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"lm\",\n",
      "                \"TAO\",\n",
      "                \"language Models\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Conversational AI\",\n",
      "                \"en-GB\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 582300065,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_en_gb_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-07-19T21:20:09.005Z\"\n",
      "},{\n",
      "    \"application\": \"OTHER\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.246Z\",\n",
      "    \"description\": \"Detect body pose from an image.\",\n",
      "    \"displayName\": \"BodyPoseNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Body pose estimation\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"TLT\",\n",
      "                \"Robotics\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 67193379,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"bodyposenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-01-19T22:51:03.295Z\"\n",
      "},{\n",
      "    \"application\": \"Speech To Text\",\n",
      "    \"createdDate\": \"2022-06-16T15:51:02.239Z\",\n",
      "    \"description\": \"Base Hindi 3-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Hindi LM\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"KenLM\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Conversational AI\",\n",
      "                \"Language Model\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"AMP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 1519069057,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"BINARY\",\n",
      "    \"name\": \"speechtotext_hi_in_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"AMP\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-07-20T02:55:20.671Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.144Z\",\n",
      "    \"description\": \"Object Detection network to detect license plates in an image of a car.\",\n",
      "    \"displayName\": \"LPDNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Object Detection\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Traffic\",\n",
      "                \"Public Safety\",\n",
      "                \"License plate detection\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"DetectNet_v2\",\n",
      "                \"Computer Vision\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 3975758,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"lpdnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-25T15:40:21.041Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:21:15.510Z\",\n",
      "    \"description\": \"Base English grammar\",\n",
      "    \"displayName\": \"Riva ASR English Inverse Normalization Grammar\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
      "    \"latestVersionSizeInBytes\": 1350491,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"FAR\",\n",
      "    \"name\": \"inverse_normalization_en_us\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-06-16T20:57:00.744Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2022-05-12T22:31:10.383Z\",\n",
      "    \"description\": \"Model to detect one or more objects from a LIDAR point cloud file and return 3D bounding boxes.\",\n",
      "    \"displayName\": \"PointPillarNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 5572394,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pointpillarnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-12T22:31:34.034Z\"\n",
      "},{\n",
      "    \"application\": \"Instance Segmentation\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.177Z\",\n",
      "    \"description\": \"1 class instance segmentation network to detect and segment instances of people in an image.\",\n",
      "    \"displayName\": \"PeopleSegNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0.2\",\n",
      "    \"latestVersionSizeInBytes\": 73969636,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"peoplesegnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-08-22T18:55:12.521Z\"\n",
      "},{\n",
      "    \"application\": \"Speech To Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-08T04:37:39.406Z\",\n",
      "    \"description\": \"English Citrinet-256 ASR model trained on ASR set 2.0, no-weight-decay\",\n",
      "    \"displayName\": \"RIVA Citrinet 256 ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Automatic_speech_recognition\",\n",
      "                \"Conversational_ai\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 41140788,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechtotext_en_us_citrinet256\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T04:49:11.919Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:57.047Z\",\n",
      "    \"description\": \"Speech to Text Jasper model for English.\",\n",
      "    \"displayName\": \"Speech to Text English Jasper\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"Jasper\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
      "    \"latestVersionSizeInBytes\": 1234711099,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"speechtotext_english_jasper\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-03-26T03:23:18.943Z\"\n",
      "},{\n",
      "    \"application\": \"Pose Estimation\",\n",
      "    \"createdDate\": \"2021-12-06T00:47:27.212Z\",\n",
      "    \"description\": \"3D human pose estimation network to predict 34 keypoints in 3D of a person in an image.\",\n",
      "    \"displayName\": \"BodyPose3DNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Smart Cities\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Computer Vision\",\n",
      "                \"Transfer Learning Toolkit\",\n",
      "                \"Deep Learning\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_performance_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 40360415,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"bodypose3dnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-12-09T20:57:24.893Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:21:53.250Z\",\n",
      "    \"description\": \"Base German grammar\",\n",
      "    \"displayName\": \"Riva ASR German Inverse Normalization Grammar\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 4128539,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"FAR\",\n",
      "    \"name\": \"inverse_normalization_de_de\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:33.127Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:53:38.600Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained DetectNet V2\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Industrial\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"DetectNet_v2\",\n",
      "                \"Smart Infrastructure\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"resnet34\",\n",
      "    \"latestVersionSizeInBytes\": 178944632,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_detectnet_v2\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-02-02T17:18:27.337Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T07:42:58.910Z\",\n",
      "    \"description\": \"Base French 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR French LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"lm\",\n",
      "                \"French\",\n",
      "                \"TAO\",\n",
      "                \"language Models\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Conversational AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 627627578,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_fr_fr_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-07-19T21:21:30.156Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.235Z\",\n",
      "    \"description\": \"4 class object detection network to detect cars in an image.\",\n",
      "    \"displayName\": \"TrafficCamNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.2\",\n",
      "    \"latestVersionSizeInBytes\": 5453692,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"trafficcamnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-25T21:59:56.894Z\"\n",
      "},{\n",
      "    \"application\": \"Punctuation and Capitalization\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-31T21:37:40.065Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for Spanish\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"Conversational-Ai\",\n",
      "                \"Riva\",\n",
      "                \"Capitalization\",\n",
      "                \"Inference\",\n",
      "                \"Punctuation\",\n",
      "                \"NLP\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\",\n",
      "                \"Spanish\",\n",
      "                \"Finetuning\",\n",
      "                \"Natural-Language-Processing\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 712289648,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_es_us_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-11T15:30:34.728Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva EA\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-17T23:00:07.376Z\",\n",
      "    \"description\": \"Base German 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR German LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"German\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 1393581375,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_de_de_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:08.874Z\"\n",
      "},{\n",
      "    \"application\": \"Classification\",\n",
      "    \"createdDate\": \"2021-08-16T15:53:38.509Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained Classification\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Industrial\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"EfficientNet\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"ResNet\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"VGG\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"cspdarknet_tiny\",\n",
      "    \"latestVersionSizeInBytes\": 29955696,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_classification\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-11-23T07:41:04.189Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"createdDate\": \"2021-08-25T15:09:45.349Z\",\n",
      "    \"description\": \"Mel-Spectrogram prediction conditioned on input text with LJSpeech voice.\",\n",
      "    \"displayName\": \"Speech Synthesis English Tacotron2\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Text to Speech\",\n",
      "                \"English\",\n",
      "                \"TTS\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Tacotron2\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 112824320,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_english_tacotron2\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:45:53.780Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva EA\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-17T23:02:17.225Z\",\n",
      "    \"description\": \"Base Russian 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Russian LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"Russian\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
      "    \"latestVersionSizeInBytes\": 2681513539,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_ru_ru_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-06-15T10:25:43.966Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-06-16T16:03:55.256Z\",\n",
      "    \"description\": \"Hindi Conformer ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Hindi - ASR set 2.0\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_2.0\",\n",
      "    \"latestVersionSizeInBytes\": 272188608,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_hi_in_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-07-19T21:32:48.290Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.369Z\",\n",
      "    \"description\": \"Detect faces from an image.\",\n",
      "    \"displayName\": \"FaceDetect\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Object Detection\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"DetectNet_v2\",\n",
      "                \"Healthcare\",\n",
      "                \"Computer Vision\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_quantized_v2.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 5775090,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"facenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-01-13T18:58:31.416Z\"\n",
      "},{\n",
      "    \"application\": \"Question Answering\",\n",
      "    \"createdDate\": \"2021-08-18T20:05:00.928Z\",\n",
      "    \"description\": \"Question Answering Megatron uncased model for extractive question answering on any provided content.\",\n",
      "    \"displayName\": \"Question Answering SQUAD2.0 Megatron\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"QA\",\n",
      "                \"NLP\",\n",
      "                \"SQUAD2.0\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Question Answering\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Megatron\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 1337603607,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"questionanswering_squad_english_megatron\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:43:28.489Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-22T00:40:20.202Z\",\n",
      "    \"description\": \"GAN-based waveform generator from mel-spectrograms.\",\n",
      "    \"displayName\": \"RIVA Hifigan Male 1\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"TTS\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"HiFiGAN\",\n",
      "                \"Speech Synthesis\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 55755743,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_en_us_hifigan_male_1\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:45:25.847Z\"\n",
      "},{\n",
      "    \"application\": \"Riva\",\n",
      "    \"createdDate\": \"2021-08-20T03:26:03.060Z\",\n",
      "    \"description\": \"Base English n-gram LM trained on LibriSpeech, Switchboard and Fisher\",\n",
      "    \"displayName\": \"Riva ASR English LM\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Finetuning\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 6244940310,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechtotext_english_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-08-26T15:43:56.947Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T18:08:01.771Z\",\n",
      "    \"description\": \"English ASR model trained on ASR Set 1.2, Noise Robust\",\n",
      "    \"displayName\": \"RIVA Jasper ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"Jasper\",\n",
      "                \"STT\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
      "    \"latestVersionSizeInBytes\": 1234711099,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_us_jasper\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:45:14.736Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-29T23:17:55.307Z\",\n",
      "    \"description\": \"Mandarin Citrinet ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR Mandarin\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Mandarin\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 583781459,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_zh_cn_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-02T09:51:30.900Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:41.798Z\",\n",
      "    \"description\": \"1 class object detection network to detect faces in an image.\",\n",
      "    \"displayName\": \"FaceDetectIR\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Object Detection\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Public Safety\",\n",
      "                \"IR\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Image Classification\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"DetectNet_v2\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 9532530,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"facedetectir\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-11-08T05:26:22.109Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.130Z\",\n",
      "    \"description\": \"4 class object detection network to detect cars in an image.\",\n",
      "    \"displayName\": \"DashCamNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.2\",\n",
      "    \"latestVersionSizeInBytes\": 6967865,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"dashcamnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-06-16T15:42:54.950Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:21:38.219Z\",\n",
      "    \"description\": \"Base Spanish grammar\",\n",
      "    \"displayName\": \"Riva ASR Spanish Inverse Normalization Grammar\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 1386195,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"FAR\",\n",
      "    \"name\": \"inverse_normalization_es_us\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:25.262Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T17:12:08.183Z\",\n",
      "    \"description\": \"English Citrinet ASR model trained on ASR set 3.0, no-weight-decay\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v3.0\",\n",
      "    \"latestVersionSizeInBytes\": 566722587,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_us_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-02T07:48:44.918Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T06:57:19.368Z\",\n",
      "    \"description\": \"French (fr-FR) Conformer ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR French\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 486732786,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_fr_fr_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-08-04T12:36:28.553Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"createdDate\": \"2021-08-25T15:09:44.822Z\",\n",
      "    \"description\": \"GAN-based waveform generator from mel-spectrograms.\",\n",
      "    \"displayName\": \"Speech Synthesis HiFi-GAN\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Text to Speech\",\n",
      "                \"TTS\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"HiFiGAN\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 51892640,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_hifigan\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:45:56.910Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva EA\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-09T01:27:18.447Z\",\n",
      "    \"description\": \"Contains files used in rmir creation\",\n",
      "    \"displayName\": \"Riva TTS English US Auxiliary Files\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Riva\",\n",
      "                \"Conversational AI\",\n",
      "                \"Speech Synthesis\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
      "    \"latestVersionSizeInBytes\": 3721630,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"n/a\",\n",
      "    \"name\": \"speechsynthesis_en_us_auxiliary_files\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-25T14:50:28.672Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-06-16T16:02:29.388Z\",\n",
      "    \"description\": \"Hindi Citrinet ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR Hindi (hi-IN) - ASR set 1.0\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"AMP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 566726299,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_hi_in_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"AMP\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-07-19T21:34:33.270Z\"\n",
      "},{\n",
      "    \"application\": \"Domain Classification\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:57.163Z\",\n",
      "    \"description\": \"Domain classification of the query for weather chat bot.\",\n",
      "    \"displayName\": \"Domain Classification English Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Domain Classification\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 440794733,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"domainclassification_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:43:45.183Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-11-23T07:36:59.791Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained EfficientDet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"efficientnet_b2\",\n",
      "    \"latestVersionSizeInBytes\": 64864720,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_efficientdet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-11-24T20:13:37.840Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:22:07.127Z\",\n",
      "    \"description\": \"Base English grammar\",\n",
      "    \"displayName\": \"Riva TTS English Normalization Grammar\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
      "    \"latestVersionSizeInBytes\": 2390007,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"FAR\",\n",
      "    \"name\": \"normalization_en_us\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-20T15:16:58.353Z\"\n",
      "},{\n",
      "    \"application\": \"Emotion Classification\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.369Z\",\n",
      "    \"description\": \"Network to classify emotions from face.\",\n",
      "    \"displayName\": \"EmotionNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"Computer Vision\",\n",
      "                \"Emotion Recognition\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 4588024,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"emotionnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-01-13T18:59:41.572Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T17:20:04.171Z\",\n",
      "    \"description\": \"Russian Citrinet ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR Russian\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"STT\",\n",
      "                \"Russian\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 566725641,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_ru_ru_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-02T08:01:23.514Z\"\n",
      "},{\n",
      "    \"application\": \"Classification\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:41.810Z\",\n",
      "    \"description\": \"Resnet18 model to classify a car crop into 1 out 20 car brands.\",\n",
      "    \"displayName\": \"VehicleMakeNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Image Classification\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Traffic\",\n",
      "                \"Public Safety\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Computer Vision\",\n",
      "                \"Vehicle Classification\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 17247772,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"vehiclemakenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-11-08T04:32:26.789Z\"\n",
      "},{\n",
      "    \"application\": \"Joint Intent and Slot classification\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:58.439Z\",\n",
      "    \"description\": \"Intent and Slot classification of the qeuries for the weather chat bot (trained on weather chat bot data).\",\n",
      "    \"displayName\": \"Joint Intent and Slot Classification Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Intent and Slot Classification\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 443298808,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"intentslotclassification_weather_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:43:36.984Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-06-15T03:16:57.901Z\",\n",
      "    \"description\": \"Rusian Conformer ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Russian - ASR set 1.0\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"Russian\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Conversational AI\",\n",
      "                \"Conformer\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 276748357,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_ru_ru_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-08-11T05:20:07.686Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"createdDate\": \"2021-08-25T15:09:44.822Z\",\n",
      "    \"description\": \"Mel-Spectrogram prediction conditioned on input text with LJSpeech voice.\",\n",
      "    \"displayName\": \"Speech Synthesis English FastPitch\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Text to Speech\",\n",
      "                \"English\",\n",
      "                \"TTS\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Fastpitch\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
      "    \"latestVersionSizeInBytes\": 82356302,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_english_fastpitch\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:45:50.037Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:41.786Z\",\n",
      "    \"description\": \"3 class object detection network to detect people in an image.\",\n",
      "    \"displayName\": \"PeopleNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Object Detection\",\n",
      "                \"Smart City\",\n",
      "                \"People Detection\",\n",
      "                \"TAO\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Robotics\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"DetectNet_v2\",\n",
      "                \"Healthcare\",\n",
      "                \"Computer Vision\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_quantized_v2.6\",\n",
      "    \"latestVersionSizeInBytes\": 89162881,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"peoplenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-26T20:07:00.247Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-22T00:41:40.605Z\",\n",
      "    \"description\": \"GAN-based waveform generator from mel-spectrograms.\",\n",
      "    \"displayName\": \"RIVA Hifigan Female 1\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"TTS\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"HiFiGAN\",\n",
      "                \"Speech Synthesis\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 55755675,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_en_us_hifigan_female_1\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:45:29.007Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-22T00:32:05.604Z\",\n",
      "    \"description\": \"Mel-Spectrogram prediction conditioned on input text with English US Male 1 voice.\",\n",
      "    \"displayName\": \"RIVA English Fastpitch Male 1\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"English\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Fastpitch\",\n",
      "                \"Speech Synthesis\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 90673011,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_en_us_fastpitch_male_1\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-19T13:46:11.073Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T18:04:05.681Z\",\n",
      "    \"description\": \"English Conformer ASR model for en-US\",\n",
      "    \"displayName\": \"RIVA Conformer ASR English(en-US)\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Conformer\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v4.0\",\n",
      "    \"latestVersionSizeInBytes\": 486998256,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_us_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-08-16T11:45:39.158Z\"\n",
      "},{\n",
      "    \"application\": \"NLP\",\n",
      "    \"createdDate\": \"2022-05-12T22:50:14.594Z\",\n",
      "    \"description\": \"Intent and Slot classification of the queries for the misty bot with BERT model trained on weather, smalltalk and POI (places of interest) data.\",\n",
      "    \"displayName\": \"Joint Intent and Slot Classification Misty Bert\",\n",
      "    \"framework\": \"TransferLearningToolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Intent and Slot Classification\",\n",
      "                \"Natural Language Processing\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"TransferLearningToolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 438931389,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"intentslotclassification_misty_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-12T22:52:30.321Z\"\n",
      "},{\n",
      "    \"application\": \"Question Answering\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:58.595Z\",\n",
      "    \"description\": \"Question Answering Bert Large uncased model for extractive question answering on any provided content.\",\n",
      "    \"displayName\": \"Question Answering SQUAD2.0 Bert - Large\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"QA\",\n",
      "                \"NLP\",\n",
      "                \"SQUAD2.0\",\n",
      "                \"TAO\",\n",
      "                \"BERT Large\",\n",
      "                \"Riva\",\n",
      "                \"Question Answering\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 438459496,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"questionanswering_squad_english_bertlarge\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:05.680Z\"\n",
      "},{\n",
      "    \"application\": \"Named Entity Recognition\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:57.311Z\",\n",
      "    \"description\": \"The model identifies a category/entity the word in the input text belongs to.\",\n",
      "    \"displayName\": \"Named Entity Recognition Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Named Entity Recognition\",\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\",\n",
      "                \"NER\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 440857990,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"namedentityrecognition_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:43:41.863Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-22T00:32:47.475Z\",\n",
      "    \"description\": \"Mel-Spectrogram prediction conditioned on input text with English US Female 1 voice.\",\n",
      "    \"displayName\": \"RIVA English Fastpitch Female 1\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"English\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Fastpitch\",\n",
      "                \"Speech Synthesis\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 90672542,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_en_us_fastpitch_female_1\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-19T13:46:53.333Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-20T17:44:38.494Z\",\n",
      "    \"description\": \"Spanish Conformer ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Spanish\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Spanish\",\n",
      "                \"Conformer\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 486998134,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_es_us_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-02T09:51:30.819Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-07-21T21:47:01.676Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods, hyphens and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for French\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 619819134,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_fr_fr_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-07-21T21:47:38.524Z\"\n",
      "},{\n",
      "    \"application\": \"Punctuation and Capitalization\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-31T21:36:59.700Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for German\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"Conversational-Ai\",\n",
      "                \"Riva\",\n",
      "                \"Capitalization\",\n",
      "                \"Inference\",\n",
      "                \"German\",\n",
      "                \"Punctuation\",\n",
      "                \"NLP\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\",\n",
      "                \"Finetuning\",\n",
      "                \"Natural-Language-Processing\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 712286911,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_de_de_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-11T15:32:27.081Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T18:12:16.343Z\",\n",
      "    \"description\": \"Base English n-gram LM trained on LibriSpeech, Switchboard and Fisher\",\n",
      "    \"displayName\": \"Riva ASR English(en-US) LM\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"LM\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Vertex AI Workbench\",\n",
      "                \"One Click Deploy\",\n",
      "                \"Vertex AI\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Quick Deploy\",\n",
      "                \"Google Cloud\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v4.0\",\n",
      "    \"latestVersionSizeInBytes\": 7996838576,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_en_us_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-07-19T08:28:23.894Z\"\n",
      "},{\n",
      "    \"application\": \"Gesture Classification\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.246Z\",\n",
      "    \"description\": \"Classify gestures from hand crop images.\",\n",
      "    \"displayName\": \"GestureNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Gesture recognition\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"Computer Vision\",\n",
      "                \"Robotics\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 46124617,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"gesturenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-01-13T18:57:38.868Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva EA\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-17T23:05:19.998Z\",\n",
      "    \"description\": \"Base Spanish 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Spanish LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Spanish\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 1067128899,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_es_us_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:48.578Z\"\n",
      "},{\n",
      "    \"application\": \"Pose Classification\",\n",
      "    \"createdDate\": \"2022-05-12T22:31:11.382Z\",\n",
      "    \"description\": \"Pose classification network to classify poses of people from their skeletons.\",\n",
      "    \"displayName\": \"Pose Classification\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 12730328,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"poseclassificationnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-12T22:31:26.218Z\"\n",
      "},{\n",
      "    \"application\": \"Character Recognition\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.268Z\",\n",
      "    \"description\": \"Model to recognize characters from the image crop of a License Plate.\",\n",
      "    \"displayName\": \"License Plate Recognition\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Traffic\",\n",
      "                \"Public Safety\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"License Plate recognition\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Computer Vision\",\n",
      "                \"OCR\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 231797006,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"lprnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-11-08T05:39:22.035Z\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# List all available models\n",
    "!ngc registry model list nvidia/tao/* --column name --column repository --column application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ab3f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"download_end\": \"2022-08-30 03:39:51.487959\",\n",
      "    \"download_start\": \"2022-08-30 03:39:46.479681\",\n",
      "    \"download_time\": \"5s\",\n",
      "    \"files_downloaded\": 1,\n",
      "    \"local_path\": \"/dli/task/tao_project/models/trafficcamnet_vunpruned_v1.0\",\n",
      "    \"size_downloaded\": \"44.33 MB\",\n",
      "    \"status\": \"Completed\",\n",
      "    \"transfer_id\": \"trafficcamnet_vunpruned_v1.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Download the unpruned pre-trained model from NGC\n",
    "!ngc registry model download-version nvidia/tao/trafficcamnet:unpruned_v1.0 \\\n",
    "    --dest $MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d8a7ac2-cf8e-4536-98a0-066dea725ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"download_end\": \"2022-08-30 03:39:57.558671\",\n",
      "    \"download_start\": \"2022-08-30 03:39:54.554232\",\n",
      "    \"download_time\": \"3s\",\n",
      "    \"files_downloaded\": 3,\n",
      "    \"local_path\": \"/dli/task/tao_project/models/trafficcamnet_vpruned_v1.0\",\n",
      "    \"size_downloaded\": \"5.2 MB\",\n",
      "    \"status\": \"Completed\",\n",
      "    \"transfer_id\": \"trafficcamnet_vpruned_v1.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Download the pruned pre-trained model from NGC\n",
    "!ngc registry model download-version nvidia/tao/trafficcamnet:pruned_v1.0 \\\n",
    "    --dest $MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03eafe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwx------ 2 root root 4096 Aug 30 03:39 trafficcamnet_vunpruned_v1.0\n",
      "drwx------ 2 root root 4096 Aug 30 03:39 trafficcamnet_vpruned_v1.0\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Check if models have been downloaded into directory\n",
    "!ls -rlt $MODELS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb57ff2-2960-4dc2-80e0-7ebae65debc8",
   "metadata": {},
   "source": [
    "**Observations**:<br>\n",
    "Below are some fields that are important to note: \n",
    "\n",
    "<p><img src='images/model_card_tao.png' width=1080></p>\n",
    "\n",
    "<p><img src='images/encryption_key.png' width=540></p>\n",
    "\n",
    "<p><img src='images/important.png' width=720></p>\n",
    "\n",
    "_Note that we're using the purpose-built TrafficCamNet model as the starting point for scene adaptation. Feel free to try the lab with other model architectures if there is time left at the end of the course. When working with purpose-built models from NGC, the correct **encryption key** is required to load the model. Users will be able to define their own export encryption key when training from a general purpose model. This is to protect proprietary IP and used to decrypt the `.etlt` model in DeepStream applications._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a21c3",
   "metadata": {},
   "source": [
    "<a name='s3'></a>\n",
    "## Prepare Data Set ##\n",
    "We're going to use annotated video data shot from the same camera at the NVIDIA headquarters parking lot for our model. It's important to recognize that the data that we're providing is limited and insufficient for training a model from scratch. Using the TAO Toolkit and transfer learning, we can use the TrafficCamNet model as the starting point and train a custom model. This is a common case when we can leverage TAO Toolkit's scene/domain adaptation capabilities. \n",
    "\n",
    "The TAO Toolkit requires the data to be in a specific format for training and evaluation: \n",
    "* The object detection tasks in the TAO Toolkit expects data in the `KITTI format`. \n",
    "    * The `images` directory contains the images to train on. \n",
    "    * The `labels` directory contains labels to the corresponding images. \n",
    "    * The `kitti_seq_to_map.json` file is _optional_ and contains a sequence to frame ID mapping for the frames in the images directory. It is useful if the data needs to be split into folds sequence wise. \n",
    "\n",
    "<p><img src='images/detection_input.png' width=720></p>\n",
    "\n",
    "* For comparison, the classification tasks expects a directory of images with the following structure, where each class has its own directory with the class name. \n",
    "\n",
    "<p><img src='images/classification_input.png' width=720></p>\n",
    "\n",
    "_You can find more details on data annotation format in the [TAO Toolkit User Guide](https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/text/data_annotation_format.html#object-detection-kitti-format)_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9dc917",
   "metadata": {},
   "source": [
    "<a name='s3.1'></a>\n",
    "### Annotation ###\n",
    "Let's preview the video before moving forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1e8b9-ccf9-4285-aa2f-46135f658087",
   "metadata": {},
   "source": [
    "Execute the below cell to view the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ad2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# View the video\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\"data/126_206-A0-3_raw.mp4\", width=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e79388",
   "metadata": {},
   "source": [
    "In addition to video feeds, we need labels to evaluate the inference results (compare the actual objects to those detected by our deep learning models), and also to expand the ground truth for training purposes. This is normally a time consuming process, but this requirement is significantly reduced with transfer learning. There are a number of annotation tools that are publically available for use. Our data set annotation was generated (manually) using [Vatic](https://github.com/cvondrick/vatic) and provided in JSON format. Each entry starts with the `track_id`, representing a unique index for each car within the recording. The `track_id` provides a set of bounding boxes and their respective bounding box positions. Below, you can see elements of the annotation format:\n",
    "\n",
    "<p><img src=\"images/vatic.jpg\" width=720></p>\n",
    "\n",
    "This is a snapshot of the JSON file for the video. We're mainly interested in the bounding box coordinates captured for our object detection model: \n",
    "* **xbr**: an integer in the range between [0, frame width], indicating the right-most location of the bounding box in coordinates relative to the frame size.<br />\n",
    "* **xtl**: an integer in the range between [0, frame width], indicating the left-most location of the bounding box in coordinates relative to the frame size.<br />\n",
    "* **ybr**: an integer in the range between [0, frame height], indicating the bottom-most location of the bounding box in coordinates relative to the frame size.<br />\n",
    "* **ytl**: an integer in the range between [0, frame height], indicating the top-most location of the bounding box in coordinates relative to the frame size.<br />\n",
    "<p><img src=\"images/json_structure.png\" width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20e908",
   "metadata": {},
   "source": [
    "Execute the cell below to preview the annotation in JSON format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d42767e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"0\": {\"boxes\": {\"0\": {\"occluded\": 0, \"ybr\": 27, \"ytl\": 15, \"xbr\": 310, \"outside\": 1, \"attributes\": [], \"xtl\": 290}, \"1\": {\"occluded\": 0, \"ybr\": 26, \"ytl\": 14, \"xbr\": 309, \"outside\": 1, \"attributes\": [], \"xtl\": 289}, \"2\": {\"occluded\": 0, \"ybr\": 26, \"ytl\": 14, \"xbr\": 309, \"outside\": 1, \"attributes\": [], \"xtl\": 289}, \"3\": {\"occluded\": 0, \"ybr\": 26, \"ytl\": 14, \"xbr\": 309, \"outside\": 1, \"attributes\": [], \"xtl\": 289}, \"4\": {\"occluded\": 0, \"ybr\": 26, \"ytl\": 14, \"xbr\": 308, \"outside\": 1, \"attributes\": [], \"xtl\": 289}, \"5\": {\"occluded\": 0, \"ybr\": 26, \"ytl\": 14, \"xbr\": 308, \"outside\": 1, \"attributes\": [], \"xtl\": 289}, \"6\": {\"occluded\": 0, \"ybr\": 25, \"ytl\": 14, \"xbr\": 308, \"outside\": 1, \"attributes\": [], \"xtl\": 289}, \"7\": {\"occluded\": 0, \"ybr\": 25, \"ytl\": 14, \"xbr\": 308, \"outside\": 1, \"attributes\": [], \"xtl\": 289}, \"8\": {\"occluded\": 0, \"ybr\": 25, \"ytl\": 14, \"xbr\": 307, \"outside\": 1, \"attributes\": [], \"xtl\": 289}, \"9\": {\"occluded\": 0, \"ybr\": 25, \"ytl\": 14, \"xbr\": 307, \"outside\": 1, \"attributes\": "
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Preview the annotation\n",
    "!cat $SOURCE_DATA_DIR/126_206-A0-3_json_sample.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79a574",
   "metadata": {},
   "source": [
    "<a name='s3.2'></a>\n",
    "### Exploratory Data Analysis ###\n",
    "We can analyze and preprocess the data using the [Pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html). We went ahead and converted the JSON files into a .csv text file for this purpose since it's otherwise a time consuming process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b2153b-d6dc-4328-bbbd-b2ec1afd1232",
   "metadata": {},
   "source": [
    "Execute the below cells to analyze the data contained in the annotation file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Load the .csv into a DataFrame\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "annotated_frames=pd.read_csv('data/annotation.csv', converters={2:ast.literal_eval})\n",
    "print(\"Length of the full DF object:\", len(annotated_frames))\n",
    "annotated_frames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0728329a-fc60-4396-9438-d640d681d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Load the .csv into a DataFrame\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "annotated_frames=pd.read_csv('data/train/_annotations.csv', converters={2:ast.literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e875a",
   "metadata": {},
   "source": [
    "We can do a `DataFrame.groupby().size()` to see how many rows there are per `frame_no`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad0069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a5a6825",
   "metadata": {},
   "source": [
    "It appears every frame has the same number of objects - 130. Here we've identified an issue with our annotation in that the bounding boxes persist even after the car has left the frame until the end of the video. We will have to filter them out with the `outside` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Filter out annotations that do not have car inside the bbox\n",
    "filtered_frames=annotated_frames[annotated_frames[\"outside\"] == 0]\n",
    "print(\"Length of the filtered DF object:\", len(filtered_frames))\n",
    "filtered_frames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b4ab7-832e-4985-9417-b5e49db7fa92",
   "metadata": {},
   "source": [
    "The filtered DataFrame is much smaller. We can plot the _Frame Indices that Include Moving Cars_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Plot frames that include moving cars\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "frames_list=list(filtered_frames['frame_no'].unique())\n",
    "frame_existance=np.zeros(annotated_frames['frame_no'].max()+1)\n",
    "for i in frames_list:\n",
    "    frame_existance[int(i)]=1\n",
    "y_pos=np.arange(len(frame_existance))\n",
    "fig, ax=plt.subplots(figsize=(18, 3))\n",
    "plt.bar(y_pos, frame_existance, align='center', alpha=0.5)\n",
    "plt.title('Frame Indices that Include Moving Cars')\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05906dc4-1e7c-4ded-93b4-efe196661e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "frames_list=list(annotated_frames['filename'].unique())\n",
    "dir_list = os.listdir('data/train/images')\n",
    "for i in dir_list:\n",
    "    if i not in frames_list:\n",
    "        p='data/train/images/'+i\n",
    "        if i[0]!='.':\n",
    "            !rm $p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef45127",
   "metadata": {},
   "source": [
    "The filtered annotated looks much more reasonable. It looks like there are many frames where there are no cars present in the frame. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e403c",
   "metadata": {},
   "source": [
    "<a name='s3.3'></a>\n",
    "### Convert Video File into Frame Images ###\n",
    "Because the object detection model operates on frame-based data, we will need to generate frames from the original movie file. To do so, we are going to use [OpenCV](https://opencv.org/) to open the video file and write a `.png` image file for each frame that has annotation. We will be using the original `.mp4` file at 10 FPS. In addition to converting video frames into `.png` images, we are creating a video for which the annotations are displayed as bounding boxes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03427fe3-bd0b-4c90-b1f1-6d38993a31db",
   "metadata": {},
   "source": [
    "Execute the below cells to create an annotated video and extract annotated images for the TAO Toolkit. This can take up to 5 mins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0dfa2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Define function to extract images and generate an annotated video\n",
    "colors = [(255, 255, 0), (255, 0, 255), (0, 255, 255), (0, 0, 255), (255, 0, 0), (0, 255, 0), (0, 0, 0), (255, 100, 0), (100, 255, 0), (100, 0, 255), (255, 0, 100)]\n",
    "\n",
    "def save_images(video_path, image_folder, frames_list, annotated_frames,  video_out_folder, fps=10):\n",
    "    # Create image folder if it doesn't exist\n",
    "    if not os.path.exists(image_folder):\n",
    "        print(\"Creating images folder\")\n",
    "        os.makedirs(image_folder)\n",
    "    \n",
    "    # Create directory for output video\n",
    "    if not os.path.exists(video_out_folder):\n",
    "        print(\"Creating video out folder\")\n",
    "        os.makedirs(video_out_folder)\n",
    "    \n",
    "    # Start reading input video\n",
    "    input_video=cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # cv2.VideoCapture().read() returns true if it has a next frame\n",
    "    retVal, im=input_video.read()\n",
    "    size=im.shape[1], im.shape[0]\n",
    "    fourcc=cv2.VideoWriter_fourcc('h','2','6','4') \n",
    "    \n",
    "    # Start writing output video\n",
    "    output_video=cv2.VideoWriter('{}/annotated_video.mp4'.format(video_out_folder), fourcc, fps, size)\n",
    "\n",
    "    frameCount=0\n",
    "    i=1\n",
    "    \n",
    "    # While has next frame\n",
    "    while retVal:\n",
    "        print(\"\\rProcessing frame no: {}\".format(frameCount), end='', flush=True)\n",
    "        \n",
    "        # If current frame is in the list of annotated frames, draw bounding box(es) and include in the output video\n",
    "        if frameCount in frames_list:\n",
    "            print(\"\\rSaving frame no: {}, index: {} out of {}\".format(frameCount, i, len(frames_list)), end='')\n",
    "            cv2.imwrite(os.path.join(image_folder, '{}.png'.format(frameCount)), im)\n",
    "            i+=1\n",
    "            frame_items=annotated_frames[annotated_frames[\"frame_no\"]==int(frameCount)]\n",
    "            for index, box in frame_items.iterrows():\n",
    "                xmin, ymin, xmax, ymax = box[\"xmin\"], box[\"ymin\"], box[\"xmax\"], box[\"ymax\"]\n",
    "                xmin2, ymin2, xmax2, ymax2 = box[\"crop\"][0], box[\"crop\"][1], box[\"crop\"][2], box[\"crop\"][3]\n",
    "                cv2.rectangle(im, (xmin, ymin), (xmax, ymax), colors[0], 1)\n",
    "                cv2.rectangle(im, (int(xmin2), int(ymin2)), (int(xmax2), int(ymax2)), colors[1], 1)\n",
    "            output_video.write(im)\n",
    "\n",
    "        # Read next frame\n",
    "        retVal, im=input_video.read()\n",
    "        frameCount+=1\n",
    "\n",
    "    input_video.release()\n",
    "    output_video.release()\n",
    "    return size        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Extract images and generate an annotated video\n",
    "save_images('{}/126_206-A0-3_raw.mp4'.format(os.environ['SOURCE_DATA_DIR']), \n",
    "            '{}/{}'.format('{}/training'.format(os.environ['DATA_DIR']), 'images'),\n",
    "            frames_list,\n",
    "            filtered_frames,\n",
    "            '{}/{}'.format(os.environ['DATA_DIR'], 'video_out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043185ff-923e-4fa4-ba55-346c2fe4ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# View the annotated output video\n",
    "Video('tao_project/data/video_out/annotated_video.mp4', width=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8dc9ad",
   "metadata": {},
   "source": [
    "<a name='s3.4'></a>\n",
    "### Generate Labels ###\n",
    "We also need to generate KITTI format labels for each frame, which is also described in the [TAO Toolkit User Guide](https://docs.nvidia.com/tao/tao-toolkit/text/data_annotation_format.html#label-files). A KITTI format label file is a simple text file containing one line per object. Each line has multiple fields. The sum of the total number of elements per object is 15 as shown below: <br>\n",
    "`class name`, `truncation`, `occlusion`, `alpha`, `xmin`, `ymin`, `xmax`, `ymax`, `height`, `weight`, `length`, `x`, `y`, `z`, `rotation_y` <br>\n",
    "Currently, for detection the TAO Toolkit only requires the class name and bbox coordinates fields to be populated. This is because the TAO Toolkit training pipe supports training only for class and bbox coordinates. The remaining fields may be set to 0 as placeholder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee5df11-9c18-4a91-82a5-fa64685686a6",
   "metadata": {},
   "source": [
    "Execute the below cells to generate the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fee05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Generate labels in KITTI format\n",
    "label_folder='{}/training/labels'.format(os.environ['DATA_DIR'])\n",
    "if not os.path.exists(label_folder):\n",
    "    print(\"Creating labels folder\")\n",
    "    os.makedirs(label_folder)\n",
    "for frame in sorted(frames_list): \n",
    "    current_frame=filtered_frames[filtered_frames['frame_no']==frame]\n",
    "    with open('{}/{}.txt'.format(label_folder, frame), 'w') as f: \n",
    "        for i, box in current_frame.iterrows(): \n",
    "            print('Writing for frame {}'.format(frame), end='\\r')\n",
    "            f.write(\"Car 0 0 0 {} {} {} {} 0 0 0 0 0 0 0\\n\".format(box['xmin'], box['ymin'], box['xmax'], box['ymax']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb0f6f5-ed79-4509-b411-bef9a2236495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing for frame 9_jpg.rf.f292a794632d736f8a321ab048604162.jpggg\r"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Generate labels in KITTI format\n",
    "label_folder='{}/train/labels'.format(os.environ['SOURCE_DATA_DIR'])\n",
    "for frame in sorted(frames_list):\n",
    "    current_frame=annotated_frames[annotated_frames['filename']==frame]\n",
    "    with open('{}/{}.txt'.format(label_folder, frame[:-4]), 'w') as f: \n",
    "        for i, box in current_frame.iterrows(): \n",
    "            print('Writing for frame {}'.format(frame), end='\\r')\n",
    "            f.write(\"Pothole 0 0 0 {} {} {} {} 0 0 0 0 0 0 0\\n\".format(box['xmin'], box['ymin'], box['xmax'], box['ymax']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88599a1d-2773-46e9-af39-f383115bee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 524\n",
      "-rw-rw-rw- 1 root root   6988 Aug 30 00:27 00_introduction.ipynb\n",
      "-rw-rw-rw- 1 root root  18694 Apr  9 19:28 01_introduction_to_the_TAO_Toolkit.ipynb\n",
      "-rw-rw-rw- 1 root root 375025 Aug 30 01:08 02_preparation_for_model_training.ipynb\n",
      "-rw-rw-rw- 1 root root  61283 Apr  9 18:56 03_model_training_with_the_TAO_Toolkit.ipynb\n",
      "-rw-rw-rw- 1 root root  33956 Apr  9 18:56 04_optimizing_a_video_AI_application.ipynb\n",
      "drwxrwxrwx 2 root root   4096 Apr  9 19:28 common\n",
      "drwxr-xr-x 4 root root   4096 Aug 30 00:52 data\n",
      "drwxrwxrwx 2 root root   4096 Apr  9 18:56 images\n",
      "drwxrwxrwx 2 root root   4096 Jun 17 19:18 logs\n",
      "drwxr-xr-x 3 root root   4096 Aug 30 00:33 ngc_assets\n",
      "drwxrwxrwx 2 root root   4096 Apr  9 18:56 sample_apps\n",
      "drwxrwxrwx 2 root root   4096 Apr  9 18:56 spec_files\n",
      "drwxr-xr-x 4 root root   4096 Aug 30 00:28 tao_project\n"
     ]
    }
   ],
   "source": [
    "!ls -l /dli/task/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "774bfd97-b827-47ae-b37c-d9c22f7454d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/tao_project/data\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['DATA_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANAGE THIS CELL\n",
    "# Preview sample KITTI format labels\n",
    "!cat $DATA_DIR/training/labels/20.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7df4f1",
   "metadata": {},
   "source": [
    "<a name='s3.5'></a>\n",
    "### Converting to TFRecords ###\n",
    "The TAO Toolkit enables converting the training data into the [**TFRecords**](https://www.tensorflow.org/tutorials/load_data/tfrecord) format, which is a simple format for storing a sequence of binary records. The TFRecord specification encodes an image frame and all the annotations associated with that frame into a single row. This can drastically help iterate faster through the data. The TAO Toolkit helps us easily convert data to TFRecord format once it's in the KITTI format. This can be done using the `dataset_convert` subtask. The `dataset_convert` tool requires a configuration file as input, which has the below parameters: \n",
    "* `kittie_config`\n",
    "    * `root_directory_path (str)`: Path to the data set root. \n",
    "    * `image_dir_name (str)`: Relative path to the directory containing images. \n",
    "    * `label_dir_name (str)`: Relative path to the directory containing labels. \n",
    "    * `partition_mode (str)`: Method _(\"random\" or \"sequence\")_ employed when partitioning the data into folds. \n",
    "    * `num_partitions (int)`: Number of partitions (folds) to split the data _(default=2)_. This field is ignored when the partition mode is set to \"random\" as by default only two partitions are generated: `train` and `val`. \n",
    "    * `image_extension (str)`: Extension of the images _(\".png\", \".jpg\", or \".jpeg\")_. \n",
    "    * `val_split (float)`: Percentage of data to be separated for validation _(0-100)_. \n",
    "    * `num_shards (int)`: The number of shards per fold _(1-20)_. When you have large amounts of samples, it is beneficial to shard your data set into multiple files as it allows inputs to 1) be read in parallel to improve throughput and 2) be shuffled better to improve performance of the model. This is particularly important when the data set is large. You can find more information on sharding on [TensorFlow's API documentation](https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset#raises_1). \n",
    "* `image_directory_path (str)`: Path to the data set root. \n",
    "\n",
    "Once generated, you can use the TFRecords across multiple training experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a5bcfc",
   "metadata": {},
   "source": [
    "<a name='e2'></a>\n",
    "#### Exercise #2 - Dataset Convert ####\n",
    "Let's use the `dataset_convert` subtask to generate TFRecords. \n",
    "\n",
    "**Instructions**:<br>\n",
    "* Modify the [TFRecords conversion spec file](spec_files/kitti_config.txt) by changing the `<FIXME>`s into the correct values and **save changes**. \n",
    "* Execute the below cells to create TFRecords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86e32483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitti_config {\n",
      "  root_directory_path: \"/dli/task/data/train\"\n",
      "  image_dir_name: \"images\"\n",
      "  label_dir_name: \"labels\"\n",
      "  image_extension: \".jpg\"\n",
      "  partition_mode: \"random\"\n",
      "  num_partitions: 2\n",
      "  val_split: 20\n",
      "  num_shards: 10\n",
      "}\n",
      "image_directory_path: \"/dli/task/data/train\"\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# View the spec file\n",
    "!cat $SPEC_FILES_DIR/kitti_config.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "638a7d55-f0ff-403d-923a-c1f877a8ba2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kitti_config {\n",
    "#   root_directory_path: \"/dli/task/tao_project/data/training\"\n",
    "#   image_dir_name: \"images\"\n",
    "#   label_dir_name: \"labels\"\n",
    "#   image_extension: \".png\"\n",
    "#   partition_mode: \"random\"\n",
    "#   num_partitions: 2\n",
    "#   val_split: 20\n",
    "#   num_shards: 10\n",
    "# }\n",
    "# image_directory_path: \"/dli/task/tao_project/data/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5120304-d725-4111-bd1f-a23e8ae31a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless==4.5.2.52\n",
      "  Downloading opencv_python_headless-4.5.2.52-cp36-cp36m-manylinux2014_x86_64.whl (38.2 MB)\n",
      "     |████████████████████████████████| 38.2 MB 37.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python-headless==4.5.2.52) (1.19.5)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.5.2.52\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python-headless==4.5.2.52 --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c1c8d-d612-40aa-9e48-843aae048fcf",
   "metadata": {},
   "source": [
    "Click ... to show **solution**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b268d7c-d554-4daf-8ce1-ee76da69e322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "usage: detectnet_v2 dataset_convert [-h] [--num_processes NUM_PROCESSES]\n",
      "                                    [--gpus GPUS]\n",
      "                                    [--gpu_index GPU_INDEX [GPU_INDEX ...]]\n",
      "                                    [--use_amp] [--log_file LOG_FILE] -d\n",
      "                                    DATASET_EXPORT_SPEC -o OUTPUT_FILENAME\n",
      "                                    [-f VALIDATION_FOLD] [-v]\n",
      "                                    {calibration_tensorfile,dataset_convert,evaluate,export,inference,prune,train}\n",
      "                                    ...\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --num_processes NUM_PROCESSES, -np NUM_PROCESSES\n",
      "                        The number of horovod child processes to be spawned.\n",
      "                        Default is -1(equal to --gpus).\n",
      "  --gpus GPUS           The number of GPUs to be used for the job.\n",
      "  --gpu_index GPU_INDEX [GPU_INDEX ...]\n",
      "                        The indices of the GPU's to be used.\n",
      "  --use_amp             Flag to enable Auto Mixed Precision.\n",
      "  --log_file LOG_FILE   Path to the output log file.\n",
      "  -d DATASET_EXPORT_SPEC, --dataset_export_spec DATASET_EXPORT_SPEC\n",
      "                        Path to the detection dataset spec containing config\n",
      "                        for exporting .tfrecords.\n",
      "  -o OUTPUT_FILENAME, --output_filename OUTPUT_FILENAME\n",
      "                        Output file name.\n",
      "  -f VALIDATION_FOLD, --validation_fold VALIDATION_FOLD\n",
      "                        Indicate the validation fold in 0-based indexing. This\n",
      "                        is required when modifying the training set but\n",
      "                        otherwise optional.\n",
      "  -v, --verbose         Flag to get detailed logs during the conversion\n",
      "                        process.\n",
      "\n",
      "tasks:\n",
      "  {calibration_tensorfile,dataset_convert,evaluate,export,inference,prune,train}\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# View dataset_convert usage\n",
    "!detectnet_v2 dataset_convert --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fce70-d634-48d6-94e1-72d5e366882a",
   "metadata": {},
   "source": [
    "When using the `dataset_convert` subtask, the `-o` argument indicates the output filename and the `-d` argument points to the path to the detection data set spec file containing the config for exporting `.tfrecord` files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14481bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "2022-08-30 03:42:57,660 - iva.detectnet_v2.dataio.build_converter - INFO - Instantiating a kitti converter\n",
      "2022-08-30 03:42:57,660 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Creating output directory /dli/task/tao_project/data/tfrecords/kitti_trainval\n",
      "2022-08-30 03:42:57,662 - iva.detectnet_v2.dataio.kitti_converter_lib - INFO - Num images in\n",
      "Train: 571\tVal: 142\n",
      "2022-08-30 03:42:57,662 - iva.detectnet_v2.dataio.kitti_converter_lib - INFO - Validation data in partition 0. Hence, while choosing the validationset during training choose validation_fold 0.\n",
      "2022-08-30 03:42:57,662 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 0\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/detectnet_v2/dataio/dataset_converter_lib.py:142: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "2022-08-30 03:42:57,662 - tensorflow - WARNING - From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/detectnet_v2/dataio/dataset_converter_lib.py:142: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/iva/detectnet_v2/dataio/kitti_converter_lib.py:283: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "2022-08-30 03:42:57,683 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 1\n",
      "2022-08-30 03:42:57,701 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 2\n",
      "2022-08-30 03:42:57,717 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 3\n",
      "2022-08-30 03:42:57,733 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 4\n",
      "2022-08-30 03:42:57,748 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 5\n",
      "2022-08-30 03:42:57,762 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 6\n",
      "2022-08-30 03:42:57,779 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 7\n",
      "2022-08-30 03:42:57,795 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 8\n",
      "2022-08-30 03:42:57,810 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 9\n",
      "2022-08-30 03:42:57,829 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'pothole': 326\n",
      "\n",
      "2022-08-30 03:42:57,829 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 0\n",
      "2022-08-30 03:42:57,888 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 1\n",
      "2022-08-30 03:42:57,959 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 2\n",
      "2022-08-30 03:42:58,018 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 3\n",
      "2022-08-30 03:42:58,083 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 4\n",
      "2022-08-30 03:42:58,145 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 5\n",
      "2022-08-30 03:42:58,206 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 6\n",
      "2022-08-30 03:42:58,271 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 7\n",
      "2022-08-30 03:42:58,334 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 8\n",
      "2022-08-30 03:42:58,398 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 9\n",
      "2022-08-30 03:42:58,468 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'pothole': 1399\n",
      "\n",
      "2022-08-30 03:42:58,468 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Cumulative object statistics\n",
      "2022-08-30 03:42:58,468 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'pothole': 1725\n",
      "\n",
      "2022-08-30 03:42:58,468 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Class map. \n",
      "Label in GT: Label in tfrecords file \n",
      "b'Pothole': b'pothole'\n",
      "For the dataset_config in the experiment_spec, please use labels in the tfrecords file, while writing the classmap.\n",
      "\n",
      "2022-08-30 03:42:58,469 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Tfrecords generation complete.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Create directory for TFRecords and delete existing files if they exist\n",
    "\n",
    "\n",
    "!mkdir -p $DATA_DIR/tfrecords && rm -rf $DATA_DIR/tfrecords/*\n",
    "\n",
    "!detectnet_v2 dataset_convert -d $SPEC_FILES_DIR/kitti_config.txt \\\n",
    "                              -o $DATA_DIR/tfrecords/kitti_trainval/kitti_trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b974f275-f29d-4ae1-8ed3-e5bf1098a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -R /dli/task/data/train/labels*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd0daf",
   "metadata": {},
   "source": [
    "Check the shards that have been created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "762b2899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 552\n",
      "-rw-r--r-- 1 root root  9647 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00000-of-00010\n",
      "-rw-r--r-- 1 root root 10205 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00001-of-00010\n",
      "-rw-r--r-- 1 root root 10334 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00002-of-00010\n",
      "-rw-r--r-- 1 root root 11261 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00003-of-00010\n",
      "-rw-r--r-- 1 root root 10394 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00004-of-00010\n",
      "-rw-r--r-- 1 root root 10147 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00005-of-00010\n",
      "-rw-r--r-- 1 root root  9462 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00006-of-00010\n",
      "-rw-r--r-- 1 root root  9522 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00007-of-00010\n",
      "-rw-r--r-- 1 root root 10515 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00008-of-00010\n",
      "-rw-r--r-- 1 root root 10867 Aug 30 03:42 kitti_trainval-fold-000-of-002-shard-00009-of-00010\n",
      "-rw-r--r-- 1 root root 42713 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00000-of-00010\n",
      "-rw-r--r-- 1 root root 41892 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00001-of-00010\n",
      "-rw-r--r-- 1 root root 42653 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00002-of-00010\n",
      "-rw-r--r-- 1 root root 41839 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00003-of-00010\n",
      "-rw-r--r-- 1 root root 40968 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00004-of-00010\n",
      "-rw-r--r-- 1 root root 42148 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00005-of-00010\n",
      "-rw-r--r-- 1 root root 41405 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00006-of-00010\n",
      "-rw-r--r-- 1 root root 40911 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00007-of-00010\n",
      "-rw-r--r-- 1 root root 40405 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00008-of-00010\n",
      "-rw-r--r-- 1 root root 42100 Aug 30 03:42 kitti_trainval-fold-001-of-002-shard-00009-of-00010\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Check the shards that have been created\n",
    "!ls -rlt $DATA_DIR/tfrecords/kitti_trainval/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae1d3a0",
   "metadata": {},
   "source": [
    "**Well Done**! When you're ready, let's move to the [next notebook](./03_model_training_with_the_TAO_Toolkit.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f613e",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
